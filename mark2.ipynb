{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessandroMirone/MBA_UkraineWar_2022/blob/main/mark2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96331ea4",
      "metadata": {
        "id": "96331ea4"
      },
      "source": [
        "### Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02013a64",
      "metadata": {
        "id": "02013a64"
      },
      "source": [
        "IMPORTANT: WHEN THE TEXTUAL PART IS DONE, RE-LINK THE NOTEBOOK:\n",
        "- import the notebook in colab \n",
        "- save it on github : this will overwrite the link to the current version \n",
        "- revrite on drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b28423",
      "metadata": {
        "id": "62b28423"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb60ea9b",
      "metadata": {
        "id": "fb60ea9b"
      },
      "source": [
        "1) description of dataset \\\n",
        "\n",
        "2) how data are organized (in this toy example and in a real situation) \\\n",
        "\n",
        "steps of the analysis - 1 - loading and preprocessing: \\\n",
        "In a distributed environment (Eg. Hadhoop) data have to be loaded into the distributed storage system. We assume this step is already carried out. Data would be in zip form to save space. \\\n",
        "after the data have been loaded, they are exported to the environments of each node with pd.read.csv(). The data are still saved as zipped file inside each node memory, but now they can be accessed.\n",
        "we can prepare them for computation using spark by creating an RDD with parallelize. In this step, only english tweets are retained -> rdd = df.parallelize(df.text[df.language = 'english']) \\\n",
        "we can then transform this rdd as to obtain a single array splitted between the nodes, with positions in the array occupied by the texts of each tweet (ie baskets): a map function will take as inputs the 'text' column's values and the pd.Series function, stacking each text content in the positions of the array. The result will be an rdd containing an array of lists split between the different nodes. Each list contain a single element (the full text) \\\n",
        "we can use another map function with split in order to separate the lists into lists of single elements, each list of single elements now occupying the corresponding position in the array. \\\n",
        "we can then apply the cleaning functions to the array: each list (every list containing the sequence of words in the corresponding text) will be cleaned and lemmatized. The result is the same, an array of lists (baskets) each containing the tokens present in the relative basket as single elements. We can directly apply the a-priori algorithm to this array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1814588e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1814588e",
        "outputId": "3ff9b2d9-42c7-40db-a120-3de59e6a6a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 38.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=8837ce8be9c24629b1569c3a67c86dbcc55c0e0fb7f1ce9f4018122ed9f31d72\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "302e50fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "302e50fb",
        "outputId": "8bda19bd-c7c1-4939-88fa-b723f0908f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "OYc9QokumiPQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYc9QokumiPQ",
        "outputId": "25b66d9a-ae77-4f24-9a16-6cab74805ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 7.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Aoyw4m9_QCG5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aoyw4m9_QCG5",
        "outputId": "8fd99ccb-c21f-4059-c012-f440ff741628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 7.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=df192ca9eeda3040499643e28fb8834faed82a38b248ff8860adb8d2403ce6bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "GEDj_jnThIEg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEDj_jnThIEg",
        "outputId": "cb07e0ac-4de4-42c7-d770-532ce9527412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 7.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a557378",
      "metadata": {
        "id": "7a557378"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "adcf33de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adcf33de",
        "outputId": "831e3281-a739-434b-feb6-65e6e7c54a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0905_UkraineCombinedTweetsDeduped.csv.gzip.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = \"alessandromirone\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"c881e45ce076cb815820c1e582302936\"\n",
        "\n",
        "!kaggle datasets download bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows -f 0905_UkraineCombinedTweetsDeduped.csv.gzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5943e2da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "5943e2da",
        "outputId": "863d30f7-24de-48a3-c3ef-c6b542e31816"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4bb10132d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#spark context\n",
        "#spark context\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config(\"spark.driver.host\", \"localhost\").config(\"spark.network.timeout\", \"300s\").master(\"local[*]\").config(\"spark.executor.memory\", \"5g\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8ff9b5ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "8ff9b5ac",
        "outputId": "84394530-5a4e-490b-8b6b-286f78d74280"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    userid         username  \\\n",
              "0                567289542    Saudi_Gazette   \n",
              "1      1244796162751655936   RussianLadies1   \n",
              "2                161871799  ZacatecasImagen   \n",
              "3       984429894829592576     pulsoguayaco   \n",
              "4               2445145434       Lyobserver   \n",
              "...                    ...              ...   \n",
              "44690  1532665429075935235  NicholasFreshne   \n",
              "44691  1557539843219066882   Ludmila_Volkov   \n",
              "44692  1565837550861828097          Tuchua2   \n",
              "44693             31095945      shaancheema   \n",
              "44694  1511594884113010690  owarino_outsuke   \n",
              "\n",
              "                                                acctdesc           location  \\\n",
              "0      Saudi Gazette is a leading English language da...       Saudi Arabia   \n",
              "1      Russia Ladies is one of the largest and most r...             Russia   \n",
              "2                        El periódico líder en Zacatecas  Zacatecas, México   \n",
              "3      🌐✈Blog de aviación, viajes y economía para via...               🇪🇨🇺🇸   \n",
              "4      The Libya Observer is a key source for compreh...            Tripoli   \n",
              "...                                                  ...                ...   \n",
              "44690  The views, information, or opinions expressed ...                USA   \n",
              "44691                                                NaN                NaN   \n",
              "44692  #staywhitUkraine a small contribution to the e...       Leipzigngerd   \n",
              "44693  I #Am #Zeeshan #Hussain #Equality #Justice (Be...     United Kingdom   \n",
              "44694  There are millions of people and the biggest m...                NaN   \n",
              "\n",
              "       following  followers  totaltweets               usercreatedts  \\\n",
              "0              2     435540       134609  2012-04-30 13:01:28.000000   \n",
              "1            903        412          554  2020-03-31 01:19:00.000000   \n",
              "2            586      23190       178163  2010-07-02 00:48:16.000000   \n",
              "3             75        324        14459  2018-04-12 13:55:51.000000   \n",
              "4             96      77763        60461  2014-04-15 08:59:11.000000   \n",
              "...          ...        ...          ...                         ...   \n",
              "44690          4         15          331  2022-06-03 10:08:29.000000   \n",
              "44691        151         29         4241  2022-08-11 01:30:24.000000   \n",
              "44692         89        579         1241  2022-09-02 23:02:57.000000   \n",
              "44693     114038      54654       193556  2009-04-14 10:34:44.000000   \n",
              "44694         25       1005         2424  2022-04-06 06:41:42.000000   \n",
              "\n",
              "                   tweetid       tweetcreatedts  ...  original_tweet_userid  \\\n",
              "0      1566576845415501824  2022-09-05 00:00:00  ...                      0   \n",
              "1      1566576846745092097  2022-09-05 00:00:00  ...                      0   \n",
              "2      1566576846795411459  2022-09-05 00:00:00  ...                      0   \n",
              "3      1566576847051264002  2022-09-05 00:00:00  ...                      0   \n",
              "4      1566576849035018240  2022-09-05 00:00:01  ...                      0   \n",
              "...                    ...                  ...  ...                    ...   \n",
              "44690  1566939152523972610  2022-09-05 23:59:40  ...                      0   \n",
              "44691  1566939158182076417  2022-09-05 23:59:42  ...                      0   \n",
              "44692  1566939194307612673  2022-09-05 23:59:50  ...                      0   \n",
              "44693  1566939215816007680  2022-09-05 23:59:56  ...                      0   \n",
              "44694  1566939223118458881  2022-09-05 23:59:57  ...                      0   \n",
              "\n",
              "      original_tweet_username in_reply_to_status_id in_reply_to_user_id  \\\n",
              "0                         NaN                     0                   0   \n",
              "1                         NaN                     0                   0   \n",
              "2                         NaN                     0                   0   \n",
              "3                         NaN                     0                   0   \n",
              "4                         NaN                     0                   0   \n",
              "...                       ...                   ...                 ...   \n",
              "44690                     NaN                     0                   0   \n",
              "44691                     NaN                     0                   0   \n",
              "44692                     NaN                     0                   0   \n",
              "44693                     NaN                     0                   0   \n",
              "44694                     NaN                     0                   0   \n",
              "\n",
              "      in_reply_to_screen_name  is_quote_status  quoted_status_id  \\\n",
              "0                         NaN            False                 0   \n",
              "1                         NaN            False                 0   \n",
              "2                         NaN            False                 0   \n",
              "3                         NaN            False                 0   \n",
              "4                         NaN            False                 0   \n",
              "...                       ...              ...               ...   \n",
              "44690                     NaN            False                 0   \n",
              "44691                     NaN            False                 0   \n",
              "44692                     NaN            False                 0   \n",
              "44693                     NaN            False                 0   \n",
              "44694                     NaN            False                 0   \n",
              "\n",
              "       quoted_status_userid  quoted_status_username  \\\n",
              "0                         0                     NaN   \n",
              "1                         0                     NaN   \n",
              "2                         0                     NaN   \n",
              "3                         0                     NaN   \n",
              "4                         0                     NaN   \n",
              "...                     ...                     ...   \n",
              "44690                     0                     NaN   \n",
              "44691                     0                     NaN   \n",
              "44692                     0                     NaN   \n",
              "44693                     0                     NaN   \n",
              "44694                     0                     NaN   \n",
              "\n",
              "                      extractedts  \n",
              "0      2022-09-05 06:22:59.378541  \n",
              "1      2022-09-05 07:15:37.978958  \n",
              "2      2022-09-05 11:31:20.980226  \n",
              "3      2022-09-05 11:31:20.967250  \n",
              "4      2022-09-05 07:15:37.907896  \n",
              "...                           ...  \n",
              "44690  2022-09-06 01:40:18.561582  \n",
              "44691  2022-09-06 01:46:48.566650  \n",
              "44692  2022-09-06 01:46:48.556311  \n",
              "44693  2022-09-06 01:46:48.546007  \n",
              "44694  2022-09-06 01:40:18.520279  \n",
              "\n",
              "[44695 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2de70132-b20f-4ebb-94dc-8d74aaac4d33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>username</th>\n",
              "      <th>acctdesc</th>\n",
              "      <th>location</th>\n",
              "      <th>following</th>\n",
              "      <th>followers</th>\n",
              "      <th>totaltweets</th>\n",
              "      <th>usercreatedts</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>tweetcreatedts</th>\n",
              "      <th>...</th>\n",
              "      <th>original_tweet_userid</th>\n",
              "      <th>original_tweet_username</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>is_quote_status</th>\n",
              "      <th>quoted_status_id</th>\n",
              "      <th>quoted_status_userid</th>\n",
              "      <th>quoted_status_username</th>\n",
              "      <th>extractedts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>567289542</td>\n",
              "      <td>Saudi_Gazette</td>\n",
              "      <td>Saudi Gazette is a leading English language da...</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>2</td>\n",
              "      <td>435540</td>\n",
              "      <td>134609</td>\n",
              "      <td>2012-04-30 13:01:28.000000</td>\n",
              "      <td>1566576845415501824</td>\n",
              "      <td>2022-09-05 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-05 06:22:59.378541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1244796162751655936</td>\n",
              "      <td>RussianLadies1</td>\n",
              "      <td>Russia Ladies is one of the largest and most r...</td>\n",
              "      <td>Russia</td>\n",
              "      <td>903</td>\n",
              "      <td>412</td>\n",
              "      <td>554</td>\n",
              "      <td>2020-03-31 01:19:00.000000</td>\n",
              "      <td>1566576846745092097</td>\n",
              "      <td>2022-09-05 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-05 07:15:37.978958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>161871799</td>\n",
              "      <td>ZacatecasImagen</td>\n",
              "      <td>El periódico líder en Zacatecas</td>\n",
              "      <td>Zacatecas, México</td>\n",
              "      <td>586</td>\n",
              "      <td>23190</td>\n",
              "      <td>178163</td>\n",
              "      <td>2010-07-02 00:48:16.000000</td>\n",
              "      <td>1566576846795411459</td>\n",
              "      <td>2022-09-05 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-05 11:31:20.980226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>984429894829592576</td>\n",
              "      <td>pulsoguayaco</td>\n",
              "      <td>🌐✈Blog de aviación, viajes y economía para via...</td>\n",
              "      <td>🇪🇨🇺🇸</td>\n",
              "      <td>75</td>\n",
              "      <td>324</td>\n",
              "      <td>14459</td>\n",
              "      <td>2018-04-12 13:55:51.000000</td>\n",
              "      <td>1566576847051264002</td>\n",
              "      <td>2022-09-05 00:00:00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-05 11:31:20.967250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2445145434</td>\n",
              "      <td>Lyobserver</td>\n",
              "      <td>The Libya Observer is a key source for compreh...</td>\n",
              "      <td>Tripoli</td>\n",
              "      <td>96</td>\n",
              "      <td>77763</td>\n",
              "      <td>60461</td>\n",
              "      <td>2014-04-15 08:59:11.000000</td>\n",
              "      <td>1566576849035018240</td>\n",
              "      <td>2022-09-05 00:00:01</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-05 07:15:37.907896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44690</th>\n",
              "      <td>1532665429075935235</td>\n",
              "      <td>NicholasFreshne</td>\n",
              "      <td>The views, information, or opinions expressed ...</td>\n",
              "      <td>USA</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>331</td>\n",
              "      <td>2022-06-03 10:08:29.000000</td>\n",
              "      <td>1566939152523972610</td>\n",
              "      <td>2022-09-05 23:59:40</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-06 01:40:18.561582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44691</th>\n",
              "      <td>1557539843219066882</td>\n",
              "      <td>Ludmila_Volkov</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151</td>\n",
              "      <td>29</td>\n",
              "      <td>4241</td>\n",
              "      <td>2022-08-11 01:30:24.000000</td>\n",
              "      <td>1566939158182076417</td>\n",
              "      <td>2022-09-05 23:59:42</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-06 01:46:48.566650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44692</th>\n",
              "      <td>1565837550861828097</td>\n",
              "      <td>Tuchua2</td>\n",
              "      <td>#staywhitUkraine a small contribution to the e...</td>\n",
              "      <td>Leipzigngerd</td>\n",
              "      <td>89</td>\n",
              "      <td>579</td>\n",
              "      <td>1241</td>\n",
              "      <td>2022-09-02 23:02:57.000000</td>\n",
              "      <td>1566939194307612673</td>\n",
              "      <td>2022-09-05 23:59:50</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-06 01:46:48.556311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44693</th>\n",
              "      <td>31095945</td>\n",
              "      <td>shaancheema</td>\n",
              "      <td>I #Am #Zeeshan #Hussain #Equality #Justice (Be...</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>114038</td>\n",
              "      <td>54654</td>\n",
              "      <td>193556</td>\n",
              "      <td>2009-04-14 10:34:44.000000</td>\n",
              "      <td>1566939215816007680</td>\n",
              "      <td>2022-09-05 23:59:56</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-06 01:46:48.546007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44694</th>\n",
              "      <td>1511594884113010690</td>\n",
              "      <td>owarino_outsuke</td>\n",
              "      <td>There are millions of people and the biggest m...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25</td>\n",
              "      <td>1005</td>\n",
              "      <td>2424</td>\n",
              "      <td>2022-04-06 06:41:42.000000</td>\n",
              "      <td>1566939223118458881</td>\n",
              "      <td>2022-09-05 23:59:57</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-09-06 01:40:18.520279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44695 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2de70132-b20f-4ebb-94dc-8d74aaac4d33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2de70132-b20f-4ebb-94dc-8d74aaac4d33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2de70132-b20f-4ebb-94dc-8d74aaac4d33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#load zipped file in environment\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('0905_UkraineCombinedTweetsDeduped.csv.gzip.zip', 'r') as zip:\n",
        "    zip.extractall()\n",
        "filename = r'0905_UkraineCombinedTweetsDeduped.csv.gzip'\n",
        "df = pd.read_csv(filename, compression='gzip', index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bda0b278",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bda0b278",
        "outputId": "15ce3cee-fc1f-49fc-b1b1-fc36187a1201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userid', 'username', 'acctdesc', 'location', 'following', 'followers',\n",
              "       'totaltweets', 'usercreatedts', 'tweetid', 'tweetcreatedts',\n",
              "       'retweetcount', 'text', 'hashtags', 'language', 'coordinates',\n",
              "       'favorite_count', 'is_retweet', 'original_tweet_id',\n",
              "       'original_tweet_userid', 'original_tweet_username',\n",
              "       'in_reply_to_status_id', 'in_reply_to_user_id',\n",
              "       'in_reply_to_screen_name', 'is_quote_status', 'quoted_status_id',\n",
              "       'quoted_status_userid', 'quoted_status_username', 'extractedts'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b6f11f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3b6f11f",
        "outputId": "dfcfcf39-5118-413b-abd9-17f72c90b4f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['en', 'es', 'ja', 'ar', 'no', 'uk', 'und', 'ru', 'zh', 'de', 'da',\n",
              "       'it', 'vi', 'fr', 'pt', 'kn', 'ka', 'et', 'iw', 'in', 'lt', 'el',\n",
              "       'fi', 'hi', 'is', 'th', 'nl', 'ca', 'eu', 'gu', 'pl', 'cy', 'tr',\n",
              "       'bg', 'ro', 'lv', 'sv', 'ur', 'tl', 'sr', 'ta', 'ko', 'cs', 'ht',\n",
              "       'fa', 'te', 'am', 'hu', 'bn', 'ml', 'mr', 'my', 'sl', 'ckb', 'ps',\n",
              "       'or', 'pa', 'ne', 'hy'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "pd.unique(df.language) #many languages, only english texts will be considered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a30b639b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a30b639b",
        "outputId": "a465f702-df14-4175-bde7-0e464e678b0c",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"“#Ukrainian President, Volodymyr #Zelenskyy has praised the work of the #Ukrainian Air Force for downing #Russian Kalibr cruise missiles, a helicopter and drones and vowed to do all to fully defend #Ukraine's skies from enemy missiles and aircraft.”https://t.co/kyZ8eGUGPp\",\n",
              " 'I SUPPORT UKRAINE 🇺🇦\\n\\nSTOP THE WAR\\n\\n#SlavaUkraini #StopRussia #StopPutin #PutinWarCriminal #NFT #NFTCommunity #LGBTQ #nftcollector #cryptoartist #NFTs #wezenaar #rickwezenaar https://t.co/sUu4PyKU9a',\n",
              " '@LPNH ooh, another #Pedoputin fondler\\n\\n#RussiaIsATerroristState #RussiaIsANaziState #NAFO',\n",
              " 'Ukrainian military in Olhyne of #Kherson region https://t.co/hxroD3wmQQ https://t.co/hxroD3wmQQ https://t.co/8YYN3s6uza',\n",
              " 'fuck a stock of laughing for Terrorist   #CIA #FBI #NATO #Cop #Cops #Police #Marines #Army #AirForce #Navy #News #BreakingNews #Worldnews #freemason #freemasons #Freemasonry',\n",
              " '#Russia to present next week in Geneva documented evidence of violations by US, #Ukraine of convention on bioweapons, the Russian Ministry of Defense says.',\n",
              " 'Beautiful #Mariupol before Putin Russified it \\n#RussiaTerroristState #visabanforrussians \\nRussia needs to pay to rebuild when it is returned to Ukraine https://t.co/UK4ecm9lyZ',\n",
              " '@oneillquigley @RueDaungier @jimfitzpatrick Sure in that case we should have never fought British Empire, or world faced down Hitler.\\n\\nNaysayers said same back then, you know.\\n\\nZelensky, Churchill and Collins are &amp; were better than the naysayers, just hope Zelenskyy wont do a Collins and accept partition of #Ukraine',\n",
              " '#stranger #RuizOrtiz #Kherson  #BORNPINK #NCT127 #clowns 1 \\n\\nif you see a 🤡 is standing behind you in this bridge, what you will do ? https://t.co/GzXYMoUy3k',\n",
              " '@apmassaro3 @Mamulashvili_M @georgian_legion Thank you @georgian_legion ! For all your amazing work in #Ukraine!',\n",
              " 'How’s that #Kherson offensive going?\\n\\nDo they need more money yet?',\n",
              " 'The #RussiaUkraine war could have been potentially avoided if meaningful negotiations were undertaken and some of #Russia’s security concerns were addressed, opines Sammad Grover https://t.co/L1g76ay9Hr',\n",
              " '“As requested by incumbent President.” \\n\\nWe thought Biden wasn’t aware of any of this? \\n\\n#FBI #Biden #Trump #LaborDay2022 https://t.co/9v09jax4Pz',\n",
              " \"✅Food delivery to the most indigent districts of Kharkiv;\\n✅Preparation for the evacuation of elderly and mothers with children;\\n✅Collecting the evidence of russia's war crimes,\\n-our day in Kharkiv in a nutshell.\\n@NeilCamilleri5 https://t.co/GMN52k6ZO4\",\n",
              " '#Gazprom announced on Friday evening an indefinite shutdown of #NordStream 1 gas pipeline. This seems to be in response to G7 decision to impose a price cap on #Russian oil.\\n#UkraineRussiaWar',\n",
              " '5/5\\nVladimir Putin decided that #Russia do not need to sell it gas to Europe to survive. It is Europe that need Russian gas and not the other way round. Putin just trampled on the usual arrogance of Western hegemony. Good move Putin! Good move!!!\\n\\n @georgegalloway @RusEmbNigeria https://t.co/8ciVnMk6Ic',\n",
              " 'A russian military man in Kharkiv Region says in an intercepted conversation that they are facing a difficult situation. #standwithukraine #Ukraine #Ukrainians #SlavaUkraini #ArmUkraine #UkraineArmy #war #Ukrainewar \\n#Warcrimes https://t.co/zpyeZWwOJb',\n",
              " '🇺🇦💪Two combat #Ukrainian aircraft at super low altitude.\\n#Ukraine #UkraineWar #UkraineRussianWar #UkraineWillWin #Ukraina #UkrainianArmy #UkraineRussiaWar https://t.co/le7rTZoa7W',\n",
              " 'Fresh losses in the command staff of the Armed Forces of Ukraine:\\n\\n1. Colonel Andrei Omelchenko\\n2. Lieutenant Colonel Alexander Kapuchin\\n\\n#Ukraine #Russia #UkraineRussia #UkrainianArmy https://t.co/pYDda3wfLs',\n",
              " 'English Shield Watch Fob St... https://t.co/gwNEcSqDfi via @topbananamall fab @topbananaantiques #dogsoftwitter #antiquejewllery #gardensoftwitter  #StandWithUkraine #antiquesilver #stopclimatechange #antiquepictures #celebritymasterchef #gardenersworld',\n",
              " '@DanKaszeta #Ukraine regardless of which. The training must be much better than that the Russian troops get. You only have to look at recent results. Just pack your toilets, washing machines and anything else you have looted and go home.',\n",
              " 'Ukraine’s army destroys a BC warehouse in the temporarily occupied Balakliya in the Kharkiv region\\n\\n#Ukraine #RussiaIsANaziState https://t.co/ua3Vqdw5II',\n",
              " 'PUTIN ‘MYSTERY LIMP’: IS RUSSIA’S PRESIDENT REALLY DYING? | PUTIN’S HEALTH ANALYSED \\nRussia-Ukraine NATO War Latest News 2022 \\n#Putin #Russia #Ukraine #NATO #RussianArmy #Russian #Russians #UkraineRussiaWar #UkraineWar #RussiaUkraineWar #UkrainianArmy\\nhttps://t.co/M6qdrGt5ts',\n",
              " '@Kalimeralynn @sophielouisecc #Russia is losing so get nato to go in and stop the war on #UkraineRussiaWar ..our lives go back to normal after victory ...unless they are lying hahaha..',\n",
              " 'Video most likely from #Kherson \\nRussian and Ukrainian sources claiming this to be a successful attack of there own.\\n\\n#counteroffensive https://t.co/dyQrMBDLXU',\n",
              " '#UkraineRussiaWar #5September \\n-Ukrainian forces from the 79th Air Assault Brigade reportedly repelled a Russian attack and captured several Russian soldiers from the separate 1st Motor Rifle Brigade\\n-Several Russian vehicles were captured by Ukrainian forces\\n#BREAKING https://t.co/bXg9FY2kfw',\n",
              " '@RussianEmbassy @mfa_russia @RusEmbUSA @RusMission_EU @FCDOGovUK @BBCWorld @SkyNews @guardian @Telegraph @FinancialTimes @TheEconomist Absolutely right. As soon as there is a change of power in Ruzzia that resembles something of a state that values human beings, we will then return to help you. Putin and his gangster cronies must leave, including you #Lavrov',\n",
              " '@bmay He is a Agent of the #Russian State and a #Traitor',\n",
              " '🇷🇺🇺🇦#UkraineRussiaWar Update: https://t.co/xZPnXJoSfP',\n",
              " '4 MEDIA CONFIRMATIONS to #Psychic #Predictions for #VladimirPutin - #France accuses #Russia over #gas supply as #Nordstream2 shutdown, Chief of #Russian #oil giant #Lukoil, critical of #Putin’s war, dies after falling out of hospital window,..in the #ebook\\nhttps://t.co/27qVUhgUCb',\n",
              " 'Forever dreaming. #russia #saveukraine🇺🇦🙏 https://t.co/nudrLFvoDW',\n",
              " 'ISIS militants claim responsibility for attack near Russian embassy in Kabul.\\n\\n#Kabul #Russia #ISIS',\n",
              " '😂Not Alamo dump. But ammo dump. #ukraine #UkraineRussianWar #RussiaIsATerroristState',\n",
              " 'Using #Ukraine to fight their #ProxyWar against #Russia, NATO has potentially started WW3. This war will spread unless citizens vote out their war-loving leaders. https://t.co/N1UFDRhyGa',\n",
              " 'When \"#Stalinist|s\" post something about the West\\'s \"military industrial complex\" I wonder if they are aware of the ration of government spending for military purposes in #Russia, technically the largest army in the world, &amp; an overall living standard below development countries.',\n",
              " '@TreasChest no word may help now, so our thoughts are with you...\\n#SlavaUkraini',\n",
              " '@PhillipsPOBrien Wear a sweater and keep the German nuclear plants open until Russia collapses upon itself.  STOP ALL RUSSIAN TOURIST VISAS.  Seize all Russian villas, apartments and country estates, including those hiding behind “beneficial ownership” structures.  #SlavaUkraini',\n",
              " 'joe biden 46 shirt, Joe Bidden President 2020, The 46th Be  Biden, Joe Biden T-Shirts, Biden 2020, Riding Unicorn, Biden on a Blue Unicorn\\n #JoeBidden #be #Tshirts #Unicorn #joe #JoeBiden #RidingUnicornBiden #biden #PlusMinusCo\\nhttps://t.co/5kr2OHTSeZ',\n",
              " \"https://t.co/CtKpUg4iNS\\n\\nConsumer Discretionary stocks are well represented in our Early Morning Movers Bearish scan. Some examples, \\nnot recommendations are: $BABA, $EXPE, $CROX, $PDD, $DASH, $CPRI. Let's see if they continue to\\nfall today. #RIPKK, $AAPL, #Russia https://t.co/2BhVf7l8Ms\",\n",
              " 'Magnifique ! #Ukraine «\\xa0Born To Be Free\\xa0» https://t.co/ezcsb6fJI5',\n",
              " '⚡️ Air defense engaging aerial targets in Vinnytsia region.\\n#UkraineRussiaWar',\n",
              " 'Now #coffee for the #Mexico produced in Russia! Due to cheap electricity, gas, and labor in #Russia, it is more profitable to shipping coffee from Brazil to Russia, roast coffee, send it to Mexico. AND IT WILL BE MORE PROFITABLE than producing such coffee in Mexico!\\n#food https://t.co/qBoMPd0jai',\n",
              " '🇬🇧 I was just announced that #liztruss is the new #primeminester of the #UK Congratulations @trussliz ‼️#Ukraine looks forward to working with you. #LizTruss #LizForLeader https://t.co/KKy4YO8vzd',\n",
              " 'https://t.co/xxvroOMsgx\\n\\U0001fae2 2nd greates military power my ass \\U0001f90c🤡',\n",
              " 'Do the Taliban regret blowing up the Bamiyan Buddhas? New government takes steps to ... https://t.co/IEkckOEkqS #war #terror #islamicstate',\n",
              " '@laurenboebert Cry me a river … #Conmantrumps sons room was searched because no one is off limits when searching a #FelonTrump potentially selling secrets to #Putin #China adversaries!',\n",
              " '@WallStreetSilv THAT is exactly what WE should be doing now...a new PM wont stop the verbal diarrhoea..if anything it will get worse...#GTTO \\n#ToriesOut60\\n#JohnsonOut224 \\n#StandWithUkraine 🇺🇦#RwandaNotInMyName\\n#TorySewageParty',\n",
              " '@ivan_8848 there will be an exodus, possibly millions\\n#Ukraine #Russia',\n",
              " 'Not using Russian gas is good for the climate.\\n\\n#ClimateCrisis #UkraineRussiaWar',\n",
              " '#BREAKING \\nRussian court jails ex-reporter #IvanSafronov for 22 years for treason \\n\\n#AFP #Moscow #Russia https://t.co/Itu0xswBg9']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "rdd = sc.parallelize(df.text[df.language == 'en'].sample(n=500,random_state=33))\n",
        "rdd.take(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57b9e110",
      "metadata": {
        "id": "57b9e110"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bmzr31WBWeqp",
      "metadata": {
        "id": "bmzr31WBWeqp"
      },
      "outputs": [],
      "source": [
        "import regex as re\n",
        "from autocorrect import Speller\n",
        "import unidecode\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "mRReII8btGz3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRReII8btGz3",
        "outputId": "1e5066b9-9380-48d2-eac4-db2a5e0e65c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemma = WordNetLemmatizer()\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = stopwords.words(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "CxNr8igjWoVq",
      "metadata": {
        "id": "CxNr8igjWoVq"
      },
      "outputs": [],
      "source": [
        "def cleantxt(x):\n",
        "    res = x.lower() #lowercase\n",
        "    \n",
        "    res = re.sub(r'<.*?>','',res) #remove html tags\n",
        "   \n",
        "    res = re.sub(r'https?://\\S+|www\\.\\S+', '', res) #remove URLs\n",
        "    \n",
        "    res = re.sub(r'\\d+', '', res) #remove numbers\n",
        "   \n",
        "    res = unidecode.unidecode(res) #convert accented characters to ascii characters\n",
        "    \n",
        "    emoji_char = re.compile(\"[\" \n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emojis\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\n",
        "                               \"]+\", flags=re.UNICODE) \n",
        "    res = emoji_char.sub(r'',res) #remove emojis, pictographs and other unusual characters\n",
        "\n",
        "    res = re.sub(\"&amp\", \"and\", res).replace(\"\\n\", \" \") #remove refuses due to encoding \n",
        "\n",
        "    res = res.translate(str.maketrans('', '', punctuation)) #remove punctuation \n",
        "\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*') #remove stopwords\n",
        "    res = pattern.sub('', res)\n",
        "\n",
        "    res = re.sub('\\s+',\" \", res) #remove whitespaces\n",
        "\n",
        "    spell_corrector = Speller(lang='en') #corrector NOTE: this is an english corrector: as a result, some slavic names may be changed\n",
        "    res = spell_corrector(res)\n",
        "               \n",
        "    \n",
        "    return res\n",
        "\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "tcbGxJJCWsKO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcbGxJJCWsKO",
        "outputId": "8dc90d2a-5823-41cf-80a6-0c589f1d4f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ukrainian president volodymyr zelenskyy praised work ukrainian air force downing russian caliber cruise missiles helicopter drones vowed fully defend ukraine skies enemy missiles aircraft',\n",
              " 'support ukraine stop war slavaukraini stoprussia stopputin putinwarcriminal nft nftcommunity lgbtq nftcollector cryptoartist nts wezenaar rickwezenaar ',\n",
              " 'link ooh another pedoputin founder russiaisaterroriststate russiaisanazistate nano',\n",
              " 'ukrainian military ohne person region ',\n",
              " 'fuck stock laughing terrorist cia fbi nato cop cops police marines army airforce navy news breakingnews worldnews freeman freemasonry freemasonry',\n",
              " 'russia present next week geneva documented evidence violations us ukraine convention bioweapons russian ministry defense says',\n",
              " 'beautiful mariupol putin justified russiaterroriststate visabanforrussians russia needs pay rebuild returned ukraine ',\n",
              " 'oneillquigley ruedaungier jimfitzpatrick sure case never fought british empire world faced hitler naysayers said back know zelensky churchill collins better naysayers hope zelenskyy wont collins accept partition ukraine',\n",
              " 'stranger ruizortiz person bornpink not clowns see standing behind bridge ',\n",
              " 'apmassaro mamulashvilim georgianlegion thank georgianlegion amazing work ukraine',\n",
              " 'how person offensive going need money yet',\n",
              " 'russiaukraine war could potentially avoided meaningful negotiations undertaken russias security concerns addressed spines ammad grove ',\n",
              " 'requested incumbent president thought biden wasnt aware fbi biden trump laborday ',\n",
              " 'food delivery incident districts khaki preparation evacuation elderly mothers children collecting evidence russias war crimes day khaki nutshell neilcamilleri ',\n",
              " 'gazprom announced friday evening indefinite shutdown nordstream gas pipeline seems response g decision impose price cap russian oil ukrainerussiawar',\n",
              " ' vladimir putin decided russia need sell gas europe survive europe need russian gas way round putin traveled usual arrogance western hegemony good move putin good move georgegalloway rusembnigeria ',\n",
              " 'russian military man khaki region says intercepted conversation facing difficult situation standwithukraine ukraine ukrainian slavaukraini armukraine ukrainearmy war ukrainewar warcrimes ',\n",
              " 'two combat ukrainian aircraft super low altitude ukraine ukrainewar ukrainerussianwar ukrainewillwin ukraina ukrainianarmy ukrainerussiawar ',\n",
              " 'fresh losses command staff armed forces ukraine colonel andrew omelchenko lieutenant colonel alexander kapuchin ukraine russia ukrainerussia ukrainianarmy ',\n",
              " 'english shield watch fob st via topbananamall fab topbananaantiques dogsoftwitter antiquejewllery gardensoftwitter standwithukraine antiquesilver stopclimatechange antiquepictures celebritymasterchef gardenersworld',\n",
              " 'dankaszeta ukraine regardless training must much better russian troops get look recent results pack toilets washing machines anything else looted go home',\n",
              " 'ukraine army destroys bc warehouse temporarily occupied balakliya khaki region ukraine russiaisanazistate ',\n",
              " 'putin mystery limp russias president really dying putin health analysed russiaukraine nato war latest news putin russia ukraine nato russianarmy russian russian ukrainerussiawar ukrainewar russiaukrainewar ukrainianarmy ',\n",
              " 'kalimeralynn sophielouisecc russia losing get nato go stop war ukrainerussiawar lives go back normal victory unless lying haha',\n",
              " 'video likely person russian ukrainian sources claiming successful attack counteroffensive ',\n",
              " 'ukrainerussiawar september ukrainian forces th air assault brigade reportedly repelled russian attack captured several russian soldiers separate st motor rifle brigade several russian vehicles captured ukrainian forces breaking ',\n",
              " 'russianembassy mfarussia rusembusa rusmissioneu fcdogovuk pcworld skynews guardian telegraph financialtimes theeconomist absolutely right soon change power russia resembles something state values human beings return help putin gangster copies must leave including lvaro',\n",
              " 'may agent russian state traitor',\n",
              " 'ukrainerussiawar update ',\n",
              " ' media confirmation psychic predictions vladimirputin france accuses russia gas supply nordstream shutdown chief russian oil giant lukoil critical putin war dies falling hospital windows ebook ',\n",
              " 'forever dreaming russia saveukraine ',\n",
              " 'isis militants claim responsibility attack near russian embassy kabul kabul russia isis',\n",
              " 'alam dump ammo dump ukraine ukrainerussianwar russiaisaterroriststate',\n",
              " 'using ukraine fight proxywar russia nato potentially started ww war spread unless citizens vote warloving leaders ',\n",
              " 'stalinists post something wests military industrial complex wonder aware ration government spending military purposes russia technically largest army world overall living standard development countries',\n",
              " 'treaschest word may help thoughts slavaukraini',\n",
              " 'phillipspobrien wear sweater keep german nuclear plants open russia collapses upon stop russian tourist visas seize russian villas apartments country estates including hiding behind beneficial ownership structures slavaukraini',\n",
              " 'joe biden shirt joe hidden president th biden joe biden shirts biden riding unicorn biden blue unicorn forbidden shirts unicorn joe joebiden ridingunicornbiden biden plusminusco ',\n",
              " ' consumer discretionary stocks well represented early morning movers parish scan examples recommendations baba expr crop add dash pri lets see continue fall today risk aap russia ',\n",
              " 'magnifique ukraine born free ',\n",
              " ' air defense engaging aerial targets vinnytsia region ukrainerussiawar',\n",
              " 'coffee mexico produced russia due cheap electricity gas labor russia profitable shipping coffee brazil russia roast coffee send mexico profitable producing coffee mexico food ',\n",
              " ' announced liztruss new primeminister uk congratulations trussliz ukraine looks forward working liztruss lizforleader ',\n",
              " ' nd greater military power ass ',\n",
              " 'taliban regret blowing bamiyan buddha new government takes steps war terror islamicstate',\n",
              " 'laurenboebert cry river conmantrumps sons room searched one limits searching felontrump potentially selling secrets putin china adversaries',\n",
              " 'wallstreetsilv exactly now new pm wont stop verbal diarrhoeaif anything get worsegtto toriesout johnsonout standwithukraine rwandanotinmyname torysewageparty',\n",
              " 'ivan exodus possibly millions ukraine russia',\n",
              " 'using russian gas good climate climatecrisis ukrainerussiawar',\n",
              " 'breaking russian court jails reporter ivansafronov years treason afp moscow russia ']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "rdd = rdd.map(cleantxt)\n",
        "rdd.take(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "-H1CTRH-Bf81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H1CTRH-Bf81",
        "outputId": "d7d6d7de-0787-46a6-b34b-557692cc0692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ukrainian',\n",
              "  'president',\n",
              "  'volodymyr',\n",
              "  'zelenskyy',\n",
              "  'praised',\n",
              "  'work',\n",
              "  'ukrainian',\n",
              "  'air',\n",
              "  'force',\n",
              "  'downing',\n",
              "  'russian',\n",
              "  'caliber',\n",
              "  'cruise',\n",
              "  'missiles',\n",
              "  'helicopter',\n",
              "  'drones',\n",
              "  'vowed',\n",
              "  'fully',\n",
              "  'defend',\n",
              "  'ukraine',\n",
              "  'skies',\n",
              "  'enemy',\n",
              "  'missiles',\n",
              "  'aircraft'],\n",
              " ['support',\n",
              "  'ukraine',\n",
              "  'stop',\n",
              "  'war',\n",
              "  'slavaukraini',\n",
              "  'stoprussia',\n",
              "  'stopputin',\n",
              "  'putinwarcriminal',\n",
              "  'nft',\n",
              "  'nftcommunity',\n",
              "  'lgbtq',\n",
              "  'nftcollector',\n",
              "  'cryptoartist',\n",
              "  'nts',\n",
              "  'wezenaar',\n",
              "  'rickwezenaar',\n",
              "  ''],\n",
              " ['link',\n",
              "  'ooh',\n",
              "  'another',\n",
              "  'pedoputin',\n",
              "  'founder',\n",
              "  'russiaisaterroriststate',\n",
              "  'russiaisanazistate',\n",
              "  'nano'],\n",
              " ['ukrainian', 'military', 'ohne', 'person', 'region', ''],\n",
              " ['fuck',\n",
              "  'stock',\n",
              "  'laughing',\n",
              "  'terrorist',\n",
              "  'cia',\n",
              "  'fbi',\n",
              "  'nato',\n",
              "  'cop',\n",
              "  'cops',\n",
              "  'police',\n",
              "  'marines',\n",
              "  'army',\n",
              "  'airforce',\n",
              "  'navy',\n",
              "  'news',\n",
              "  'breakingnews',\n",
              "  'worldnews',\n",
              "  'freeman',\n",
              "  'freemasonry',\n",
              "  'freemasonry'],\n",
              " ['russia',\n",
              "  'present',\n",
              "  'next',\n",
              "  'week',\n",
              "  'geneva',\n",
              "  'documented',\n",
              "  'evidence',\n",
              "  'violations',\n",
              "  'us',\n",
              "  'ukraine',\n",
              "  'convention',\n",
              "  'bioweapons',\n",
              "  'russian',\n",
              "  'ministry',\n",
              "  'defense',\n",
              "  'says'],\n",
              " ['beautiful',\n",
              "  'mariupol',\n",
              "  'putin',\n",
              "  'justified',\n",
              "  'russiaterroriststate',\n",
              "  'visabanforrussians',\n",
              "  'russia',\n",
              "  'needs',\n",
              "  'pay',\n",
              "  'rebuild',\n",
              "  'returned',\n",
              "  'ukraine',\n",
              "  ''],\n",
              " ['oneillquigley',\n",
              "  'ruedaungier',\n",
              "  'jimfitzpatrick',\n",
              "  'sure',\n",
              "  'case',\n",
              "  'never',\n",
              "  'fought',\n",
              "  'british',\n",
              "  'empire',\n",
              "  'world',\n",
              "  'faced',\n",
              "  'hitler',\n",
              "  'naysayers',\n",
              "  'said',\n",
              "  'back',\n",
              "  'know',\n",
              "  'zelensky',\n",
              "  'churchill',\n",
              "  'collins',\n",
              "  'better',\n",
              "  'naysayers',\n",
              "  'hope',\n",
              "  'zelenskyy',\n",
              "  'wont',\n",
              "  'collins',\n",
              "  'accept',\n",
              "  'partition',\n",
              "  'ukraine'],\n",
              " ['stranger',\n",
              "  'ruizortiz',\n",
              "  'person',\n",
              "  'bornpink',\n",
              "  'not',\n",
              "  'clowns',\n",
              "  'see',\n",
              "  'standing',\n",
              "  'behind',\n",
              "  'bridge',\n",
              "  ''],\n",
              " ['apmassaro',\n",
              "  'mamulashvilim',\n",
              "  'georgianlegion',\n",
              "  'thank',\n",
              "  'georgianlegion',\n",
              "  'amazing',\n",
              "  'work',\n",
              "  'ukraine']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "rdd = rdd.map(lambda x: x.split(' ')) #\"tokenization\" (basket creation)\n",
        "rdd.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ZGzOqzE3S6Ha",
      "metadata": {
        "id": "ZGzOqzE3S6Ha"
      },
      "outputs": [],
      "source": [
        "def lem(res): #define lemmatization function (to be improved with POS)\n",
        "    for i in range(len(res)):\n",
        "        res[i] = lemma.lemmatize(res[i]) #lemmatize\n",
        "    \n",
        "    res = list(filter(None, res)) #remove NA elements still in the baskets\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3ma-AgF6TiLs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ma-AgF6TiLs",
        "outputId": "91104d91-f9ec-47d9-8658-ecf7abbfc2db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ukrainian',\n",
              "  'president',\n",
              "  'volodymyr',\n",
              "  'zelenskyy',\n",
              "  'praised',\n",
              "  'work',\n",
              "  'ukrainian',\n",
              "  'air',\n",
              "  'force',\n",
              "  'downing',\n",
              "  'russian',\n",
              "  'caliber',\n",
              "  'cruise',\n",
              "  'missile',\n",
              "  'helicopter',\n",
              "  'drone',\n",
              "  'vowed',\n",
              "  'fully',\n",
              "  'defend',\n",
              "  'ukraine',\n",
              "  'sky',\n",
              "  'enemy',\n",
              "  'missile',\n",
              "  'aircraft'],\n",
              " ['support',\n",
              "  'ukraine',\n",
              "  'stop',\n",
              "  'war',\n",
              "  'slavaukraini',\n",
              "  'stoprussia',\n",
              "  'stopputin',\n",
              "  'putinwarcriminal',\n",
              "  'nft',\n",
              "  'nftcommunity',\n",
              "  'lgbtq',\n",
              "  'nftcollector',\n",
              "  'cryptoartist',\n",
              "  'nt',\n",
              "  'wezenaar',\n",
              "  'rickwezenaar'],\n",
              " ['link',\n",
              "  'ooh',\n",
              "  'another',\n",
              "  'pedoputin',\n",
              "  'founder',\n",
              "  'russiaisaterroriststate',\n",
              "  'russiaisanazistate',\n",
              "  'nano'],\n",
              " ['ukrainian', 'military', 'ohne', 'person', 'region'],\n",
              " ['fuck',\n",
              "  'stock',\n",
              "  'laughing',\n",
              "  'terrorist',\n",
              "  'cia',\n",
              "  'fbi',\n",
              "  'nato',\n",
              "  'cop',\n",
              "  'cop',\n",
              "  'police',\n",
              "  'marine',\n",
              "  'army',\n",
              "  'airforce',\n",
              "  'navy',\n",
              "  'news',\n",
              "  'breakingnews',\n",
              "  'worldnews',\n",
              "  'freeman',\n",
              "  'freemasonry',\n",
              "  'freemasonry'],\n",
              " ['russia',\n",
              "  'present',\n",
              "  'next',\n",
              "  'week',\n",
              "  'geneva',\n",
              "  'documented',\n",
              "  'evidence',\n",
              "  'violation',\n",
              "  'u',\n",
              "  'ukraine',\n",
              "  'convention',\n",
              "  'bioweapon',\n",
              "  'russian',\n",
              "  'ministry',\n",
              "  'defense',\n",
              "  'say'],\n",
              " ['beautiful',\n",
              "  'mariupol',\n",
              "  'putin',\n",
              "  'justified',\n",
              "  'russiaterroriststate',\n",
              "  'visabanforrussians',\n",
              "  'russia',\n",
              "  'need',\n",
              "  'pay',\n",
              "  'rebuild',\n",
              "  'returned',\n",
              "  'ukraine'],\n",
              " ['oneillquigley',\n",
              "  'ruedaungier',\n",
              "  'jimfitzpatrick',\n",
              "  'sure',\n",
              "  'case',\n",
              "  'never',\n",
              "  'fought',\n",
              "  'british',\n",
              "  'empire',\n",
              "  'world',\n",
              "  'faced',\n",
              "  'hitler',\n",
              "  'naysayer',\n",
              "  'said',\n",
              "  'back',\n",
              "  'know',\n",
              "  'zelensky',\n",
              "  'churchill',\n",
              "  'collins',\n",
              "  'better',\n",
              "  'naysayer',\n",
              "  'hope',\n",
              "  'zelenskyy',\n",
              "  'wont',\n",
              "  'collins',\n",
              "  'accept',\n",
              "  'partition',\n",
              "  'ukraine'],\n",
              " ['stranger',\n",
              "  'ruizortiz',\n",
              "  'person',\n",
              "  'bornpink',\n",
              "  'not',\n",
              "  'clown',\n",
              "  'see',\n",
              "  'standing',\n",
              "  'behind',\n",
              "  'bridge'],\n",
              " ['apmassaro',\n",
              "  'mamulashvilim',\n",
              "  'georgianlegion',\n",
              "  'thank',\n",
              "  'georgianlegion',\n",
              "  'amazing',\n",
              "  'work',\n",
              "  'ukraine']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "rdd = rdd.map(lem) #apply lemmatization\n",
        "rdd.cache()\n",
        "rdd.take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7223ac09",
      "metadata": {
        "id": "7223ac09"
      },
      "source": [
        "### Algorithm "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "216eeb45",
      "metadata": {
        "id": "216eeb45"
      },
      "source": [
        "1) description of the apriori algorithm \\\n",
        "2) implementation of apriori in spark \\\n",
        "actual code for implementations ( along with description of what's happening (point 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "48ddbbe8",
      "metadata": {
        "id": "48ddbbe8"
      },
      "outputs": [],
      "source": [
        "# a priori implementation; phase 1\n",
        "# count frequency of each item (word) #WARNING: this function is extremly slow in a local setting\n",
        "\n",
        "def count_freq(rdd):\n",
        "    return (rdd.flatMap(lambda x: x)\n",
        "            .map(lambda word: (word, 1)).\n",
        "            reduceByKey(lambda a,b: a+b))\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3362da4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3362da4e",
        "outputId": "6d032d38-b6a2-4ccb-9274-b2ab3c207896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ukrainian', 59),\n",
              " ('volodymyr', 2),\n",
              " ('zelenskyy', 6),\n",
              " ('praised', 2),\n",
              " ('work', 13),\n",
              " ('missile', 7),\n",
              " ('helicopter', 2),\n",
              " ('defend', 7),\n",
              " ('sky', 1),\n",
              " ('enemy', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "freq = count_freq(rdd) #all words frequencies\n",
        "freq.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = freq.map(lambda x : x[0])\n",
        "unique_words.cache()#rdd with all words in corpus\n",
        "unique_words.take(10)"
      ],
      "metadata": {
        "id": "SUWsb1c9MkUp",
        "outputId": "2e4ea25d-c516-4465-cff8-c4a0e423715d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SUWsb1c9MkUp",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ukrainian',\n",
              " 'volodymyr',\n",
              " 'zelenskyy',\n",
              " 'praised',\n",
              " 'work',\n",
              " 'missile',\n",
              " 'helicopter',\n",
              " 'defend',\n",
              " 'sky',\n",
              " 'enemy']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b8f4a216",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8f4a216",
        "outputId": "3f498b7e-2414-4d84-92ce-91482545842f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ukrainian', 59),\n",
              " ('putin', 66),\n",
              " ('russian', 139),\n",
              " ('ukraine', 214),\n",
              " ('war', 61),\n",
              " ('russia', 182),\n",
              " ('biden', 69)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "def threshold(x): \n",
        "    return True if x[1] > 50 else False #we define the threshold at 10% (50 for 500 tweets, 4400 for 44000)\n",
        "tab = freq.filter(threshold)\n",
        "tab.take(10) #most frequent words and corresponding frequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f9f07b57",
      "metadata": {
        "id": "f9f07b57"
      },
      "outputs": [],
      "source": [
        "def count_comb(x): #define function to identify combinations'presence in the baskets\n",
        "    y=list(\"a\"*len(x[1]))\n",
        "    for i in range(len(x[1])):\n",
        "        if x[1][i] not in x[0]:\n",
        "            continue\n",
        "        else:\n",
        "            y[i]=x[1][i]\n",
        "            \n",
        "    if \"a\" not in y:\n",
        "        return tuple(y)\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5f28c729",
      "metadata": {
        "id": "5f28c729"
      },
      "outputs": [],
      "source": [
        "def unpack(tup): #define function to unpack previously formed combinations for processing\n",
        "    t=tuple()\n",
        "    for x in tup:\n",
        "        if not type(x) == list:\n",
        "            t +=(x,)\n",
        "        else:\n",
        "            t +=(*x,)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeReplica(record): #define function to remove permutations of a combination\n",
        "\n",
        "    if(isinstance(record[0], tuple)):\n",
        "        x1 = record[0]\n",
        "        x2 = record[1]\n",
        "    else:\n",
        "        x1 = [record[0]]\n",
        "        x2 = record[1]\n",
        "\n",
        "    if(any(x == x2 for x in x1) == False):\n",
        "        a = list(x1)\n",
        "        a.append(x2)\n",
        "        a.sort()\n",
        "        result = tuple(a)\n",
        "        return result \n",
        "    else:\n",
        "        return x1"
      ],
      "metadata": {
        "id": "f_EKdxqX3cRp"
      },
      "id": "f_EKdxqX3cRp",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f811b9",
      "metadata": {
        "id": "a9f811b9"
      },
      "outputs": [],
      "source": [
        "c=2\n",
        "d=1\n",
        "while(tab.isEmpty() == False):\n",
        "\n",
        "    tab_words = tab.map(lambda x : x[0]) #collect combinations of frequent words of recurrently created frequency tables\n",
        "    tab_words = tab_words.map(lambda x : [x[i] for i in range(len(x)) if type(x) == tuple]) #convert previous combinations (tuples) into modifiable lists to add the next word as part of the same object\n",
        "    tab_words.cache()\n",
        "    combined = unique_words.cartesian(tab_words) #create all possible combinations with words in the table created in the previous iteration\n",
        "    combined = combined.map(unpack) #add the next word to the combination\n",
        "    combined.cache()\n",
        "    combined = combined.map(lambda x: removeReplica(x)) #remove duplicates and permutations\n",
        "    combined = combined.filter(lambda x: len(x) == c)\n",
        "    combined.cache()\n",
        "    combined_2 = rdd.cartesian(combined) # build the confront table: here each of the combinations of frequent words are associated to each basket\n",
        "    combined_2.cache()\n",
        "    combined_2 = combined_2.map(count_comb) #retain combinations if they appear in at least a basket\n",
        "    combined_2.cache()\n",
        "    combined_2 = combined_2.filter(lambda x : x is not None) #clean output of previous step\n",
        "    combined_2.cache()\n",
        "    combined_2 = combined_2.map(lambda x: (x , 1)) #assign the counters to the combinations\n",
        "    combined_2.cache()\n",
        "    combined_2 = combined_2.reduceByKey(lambda a,b: a+b) #count the frequency of the combinations\n",
        "    combined_2.cache()\n",
        "    combined_2 = combined_2.filter(lambda x: x[1] >= 50) #retain only frequent combinations\n",
        "    combined_2.cache()\n",
        "\n",
        "    while d == 1:\n",
        "        result = combined_2\n",
        "        d +=1\n",
        "    result = result.union(combined_2).distinct() #create the output table\n",
        "    result.cache() \n",
        "    tab = combined_2 #initialize the next table\n",
        "    tab.cache()\n",
        "    c += 1 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ_X0B2kFsCL",
        "outputId": "c490f743-0047-475b-c88f-1973473d155e"
      },
      "id": "iZ_X0B2kFsCL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('ukraine', 'russian'), 52),\n",
              " (('putin', 'putin'), 58),\n",
              " (('ukraine', 'russia'), 60),\n",
              " (('ukraine', 'ukraine'), 192),\n",
              " (('war', 'war'), 57),\n",
              " (('russian', 'russian'), 120),\n",
              " (('russia', 'ukraine'), 60),\n",
              " (('russian', 'ukraine'), 52),\n",
              " (('biden', 'biden'), 52),\n",
              " (('russia', 'russia'), 159)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ceabb55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8ceabb55",
        "outputId": "0ab4c354-c69f-4a66-e03a-5e4556de4703"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2086c7ea75b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtab_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtab_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtab_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 1 times, most recent failure: Lost task 0.0 in stage 23.0 (TID 23) (39535b478b30 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-26-49202bdc721a>\", line 8, in <lambda>\n  File \"<ipython-input-25-784dbc07bdf7>\", line 13, in removeReplica\nTypeError: '<' not supported between instances of 'tuple' and 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.rdd.CartesianRDD.$anonfun$compute$1(CartesianRDD.scala:76)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-26-49202bdc721a>\", line 8, in <lambda>\n  File \"<ipython-input-25-784dbc07bdf7>\", line 13, in removeReplica\nTypeError: '<' not supported between instances of 'tuple' and 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.rdd.CartesianRDD.$anonfun$compute$1(CartesianRDD.scala:76)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "tab_words = tab.map(lambda x : x[0])\n",
        "tab_words.cache()\n",
        "tab_words.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4466bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fb4466bf",
        "outputId": "a0afe207-df30-4cd6-ec69-6ecbc03e51d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-bb381f70f002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcartesian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 27.0 failed 1 times, most recent failure: Lost task 0.0 in stage 27.0 (TID 27) (39535b478b30 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-26-49202bdc721a>\", line 8, in <lambda>\n  File \"<ipython-input-25-784dbc07bdf7>\", line 13, in removeReplica\nTypeError: '<' not supported between instances of 'tuple' and 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.rdd.CartesianRDD.$anonfun$compute$1(CartesianRDD.scala:76)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-26-49202bdc721a>\", line 8, in <lambda>\n  File \"<ipython-input-25-784dbc07bdf7>\", line 13, in removeReplica\nTypeError: '<' not supported between instances of 'tuple' and 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:765)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:747)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.rdd.CartesianRDD.$anonfun$compute$1(CartesianRDD.scala:76)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:352)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1525)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1435)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1499)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1322)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:115)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
          ]
        }
      ],
      "source": [
        "combined = unique_words.cartesian(tab_words)\n",
        "combined.cache()\n",
        "combined.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tab_words = tab.map(lambda x : x[0]) #collect combinations of frequent words of recurrently created frequency tables\n",
        "tab_words = tab_words.map(lambda x : [x[i] for i in range(len(x))]) #convert previous combinations (tuples) into modifiable lists to add the next word as part of the same object\n",
        "tab_words.cache()\n",
        "combined = unique_words.cartesian(tab_words) #create all possible combinations with words in the table created in the previous iteration\n",
        "combined = combined.map(unpack) #add the next word to the combination\n",
        "combined.cache()"
      ],
      "metadata": {
        "id": "9iuVGZKXPjbd",
        "outputId": "78a26a36-3973-4ab1-af2b-dff5e2194577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9iuVGZKXPjbd",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[19] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idm5wxMyPnV9",
        "outputId": "48e4c42f-34ac-4b74-a8e7-a25123ad5a49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "idm5wxMyPnV9",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ukrainian', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('ukrainian', 'p', 'u', 't', 'i', 'n'),\n",
              " ('volodymyr', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('zelenskyy', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('volodymyr', 'p', 'u', 't', 'i', 'n'),\n",
              " ('zelenskyy', 'p', 'u', 't', 'i', 'n'),\n",
              " ('praised', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('work', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('missile', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n'),\n",
              " ('helicopter', 'u', 'k', 'r', 'a', 'i', 'n', 'i', 'a', 'n')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3cf923",
      "metadata": {
        "id": "6f3cf923"
      },
      "source": [
        "### Scalability "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6d4f154",
      "metadata": {
        "id": "a6d4f154"
      },
      "source": [
        "how spark allow to scale the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849b6e01",
      "metadata": {
        "id": "849b6e01"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67150535",
      "metadata": {
        "id": "67150535"
      },
      "source": [
        "Showcase of results and association rules retrieved from it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "532a4af2",
      "metadata": {
        "id": "532a4af2"
      },
      "source": [
        "### conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595f161e",
      "metadata": {
        "id": "595f161e"
      },
      "source": [
        "considerations about the results and further comments"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}